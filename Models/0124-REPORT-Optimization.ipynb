{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Using Optimization in Genetic Algorithms</center>\n",
    "\n",
    "<center>by Katrina Gensterblum</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Our research goal focuses on combining genetic algorithms with image segmentation processes. The points where image segmentation algorithms are used, we already utilize libraries available through scikit-image. These libraries should already run developed code that others have previously attempted to optimize. Thus, our focus will be on optimizing the genetic algorithm part of our code, as that currently contains the greatest potential for improvement. Given this area, there are several points where optimization could aid in the overall performance including through constructing a smaller search space, altering the mutation process, and parallelizing the genetic algorithm.  \n",
    "\n",
    "The search space for our genetic algorithm consists of every parameter used in the segmentation algorithms we are searching over, as well as the range of values that each parameter could be. Currently, this search space in constructed in a very basic way. No information is shared between parameters, or their respective ranges. The search space is very thorough, but subsequently very large. The genetic algorithm is forced to search over all these values, which slows it down significantly. Building a smaller search space could be a quick and easy way to improve the performance of our algorithm.  \n",
    "\n",
    "One way in which we could achieve this decrease in size, is by combining similar parameters. For example, five distinct parameters search over the same range of values \\[0, 10000). These could easily be combined into one parameter that searches over this range and is reused for multiple image segmentation algorithms. We could even take this idea one step further and normalize all parameters which search over an integer range and reuse this single parameter for up to nine distinct parameters. This example alone would decrease our search space by over 30\\%. This level of compression in our search space would yield significant results in speeding up our genetic algorithm and would be a good starting point for optimizing our code.   \n",
    "\n",
    "Along with decreasing the number of parameters to search over, we could also decrease the range of values that these parameters could be. To do this, we could implement the search space reduction technique (SSRT) proposed by Das and Pratihar [1]. Their proposed technique systematically decreases the search space range for a parameter based on the fitness values of the population. Their results from using this technique with ten different algorithms, show that the genetic algorithm converges faster every time when using it. Since the process looks easy to incorporate with our current genetic algorithm function and produced these impressive results, it could be beneficial to include it.  \n",
    "\n",
    "Besides solely focusing on the search space, we could also optimize the mutation process in the genetic algorithm. One way to do this could be to perform sequential mutation with our algorithm [2]. In sequential mutation, mutation is performed on only one parameter per generation. The specific parameter chosen changes sequentially with each generation, hence the name of the process. Like decreasing the size of our search space, incorporating sequential mutation could also increase the speed at which our genetic algorithm converges.   \n",
    "\n",
    "Along with sequential mutation, we could also optimize the mutation process by finding an optimal mutation rate. This rate acts as a probability that dictates if a parameter for an individual will mutate or not. Studies have been conducted attempting to find the optimal mutation rate for other genetic algorithm constructions and have found that the choice of mutation rate could yield exponential speed up [3]. Given the potential improvements, it might be worthwhile to experiment with different rates in an attempt to discover an optimal one for our problem.  \n",
    "\n",
    "Finally, a third option we could implement to optimize our genetic algorithm would be to parallelize our code. The possibilities on how to do this are endless. There are many points within the genetic algorithm process in which parallelization could be introduced, and if done well, these points could build off each other to form an increasingly faster program. The simplest way to begin parallelizing our code would be to incorporate primary-replica parallelization when evaluating each of the individuals in our population [4]. Since this process relies exclusively on the individual, each evaluation process can be easily run simultaneously. Since we are working with populations of around 500 individuals, this alone would significantly decrease the computational time required.  \n",
    "\n",
    "To keep the parallelization simple, we could stop at just performing the evaluations simultaneously and having our program wait until all evaluations were completed before moving on. However, we could also speed up our program even more by allowing the genetic algorithm to continue forward, even while some evaluations are still being completed. This way the speed of our program would not be limited by the slowest segmentation algorithm options we include.   \n",
    "\n",
    "The above methods each offer a unique perspective on how to improve the overall performance of our code using different techniques. Between focusing on the search space, mutation process, and parallelization, there are many opportunities to use optimization with genetic algorithms, and this by no means covers all of them. However, with these three options alone, significant improvements can be made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### References\n",
    "\n",
    "[\\[1\\]](https://link.springer.com/content/pdf/10.1007%2F978-981-13-1540-4_12.pdf) Das, Amit Kumar, and Dilip Kumar Pratihar. “A New Search Space Reduction Technique for Genetic Algorithms.” Advances in Intelligent Systems and Computing Contemporary Advances in Innovative and Applicable Information Technology, 2018, pp. 111–119.  \n",
    "\n",
    "[\\[2\\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5362810) Nia, Mehdi Baradaran, and Yousef Alipouri. “Speeding Up the Genetic Algorithm Convergence Using Sequential Mutation and Circular Gene Methods.” Ninth International Conference on Intelligent Systems Design and Applications, 2009.  \n",
    "\n",
    "[\\[3\\]](https://arxiv.org/pdf/1703.03334.pdf) Doerr, Benjamin, et al. “Fast Genetic Algorithms.” Proceedings of the Genetic and Evolutionary Computation Conference, 2017.  \n",
    "\n",
    "[\\[4\\]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=820127&tag=1) Nowostawski, Mariusz, and Riccardo Poli. “Parallel Genetic Algorithm Taxonomy.” Third International Conference on Knowledge-Based Intelligent Information Engineering Systems. Proceedings, 1999.  \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
